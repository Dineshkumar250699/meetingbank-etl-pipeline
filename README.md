ğŸ“Š MeetingBank ETL Pipeline with Apache Airflow & Docker

An end-to-end automated ETL (Extract, Transform, Load) pipeline built using Apache Airflow, Docker, PostgreSQL, and MongoDB to process the MeetingBank dataset and generate analytical HTML reports.

This project demonstrates data engineering best practices, workflow orchestration, containerization, and automated reporting.

ğŸš€ Project Overview

The MeetingBank ETL Pipeline automates the complete lifecycle of meeting data processing:

Extract raw meeting transcripts

Clean & validate data

Transform data into structured & unstructured formats

Load data into relational (PostgreSQL) and NoSQL (MongoDB) databases

Run analytics

Generate detailed HTML reports automatically

All steps are orchestrated using Apache Airflow DAGs and executed inside Docker containers.

ğŸ§± Architecture
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ MeetingBankâ”‚
                â”‚   Dataset  â”‚
                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚  Extract   â”‚
                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚   Clean    â”‚
                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚ Transform  â”‚
                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL DB    â”‚   â”‚   MongoDB DB       â”‚
â”‚ (Structured Data) â”‚   â”‚ (Unstructured Data)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Analytics  â”‚
               â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ HTML Report Auto â”‚
            â”‚   Generation     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ› ï¸ Tech Stack
Component	Technology
Workflow Orchestration	Apache Airflow
Containerization	Docker & Docker Compose
Programming Language	Python 3
Relational Database	PostgreSQL
NoSQL Database	MongoDB
Analytics	Pandas, Python
Reporting	HTML (auto-generated)
ğŸ“ Project Structure
meetingbank_pipeline/
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ meetingbank_etl_pipeline.py   # Airflow DAG
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ clean.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ load.py
â”‚   â”œâ”€â”€ analytics.py
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql
â”‚   â”œâ”€â”€ create_indexes.sql
â”‚   â””â”€â”€ sample_queries.sql
â”‚
â”œâ”€â”€ Reports/
â”‚   â”œâ”€â”€ meetingbank_report_YYYY-MM-DD.html
â”‚   â””â”€â”€ meetingbank_detailed_report_YYYY-MM-DD.html
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit tests for ETL stages
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ï¸ How to Run the Project
1ï¸âƒ£ Prerequisites

Docker Desktop installed

Git installed

Minimum 8 GB RAM recommended

2ï¸âƒ£ Clone the Repository
git clone https://github.com/Dineshkumar250699/meetingbank-etl-pipeline.git
cd meetingbank-etl-pipeline

3ï¸âƒ£ Start Services with Docker
docker compose up -d


This will start:

Airflow Webserver

Airflow Scheduler

PostgreSQL

MongoDB

4ï¸âƒ£ Access Airflow UI

Open browser:

http://localhost:8080


Default credentials:

Username: airflow

Password: airflow

5ï¸âƒ£ Run the DAG

Enable meetingbank_etl_pipeline

Trigger the DAG manually or wait for scheduled run

Monitor tasks in Graph View

ğŸ”„ Airflow DAG Tasks
Task	Description
fetch_data	Extracts MeetingBank data
clean_data	Cleans and validates data
transform_data	Structures data
load_to_postgres	Loads structured data
load_to_mongodb	Loads unstructured data
run_analytics	Computes analytics
generate_html_report	Creates HTML report
end_task	Pipeline completion
ğŸ“Š HTML Report Output

After a successful DAG run, reports are generated automatically in:

Reports/


Example:

meetingbank_report_2025-12-27.html

meetingbank_detailed_report_2025-12-27.html

These reports include:

Pipeline execution summary

Analytics results

Data statistics

Execution timestamps

ğŸ§ª Testing

Unit tests are available under:

tests/


Run locally (optional):

pytest tests/

ğŸ§  Key Learning Outcomes

Apache Airflow DAG design

Task dependencies & retries

Dockerized data pipelines

Multi-database loading (SQL + NoSQL)

Automated analytics & reporting

Git & GitHub workflow

ğŸ“Œ Future Improvements

Add CI/CD with GitHub Actions

Add data quality checks

Store reports in cloud storage (S3/GCS)

Add interactive dashboards (Streamlit / Power BI)

ğŸ‘¤ Author

Dineshkumar Swaminathan
Masterâ€™s in Applied Data Science & AI
GitHub: Dineshkumar250699